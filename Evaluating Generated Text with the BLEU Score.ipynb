{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Generated Text with the BLEU Score\n",
    "* BLEU(Bilingual Evaluation Understudy) is a score for computing a candidate translation of text to one or more reference translations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentence BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this','is','a','test'],['this','is','test']]\n",
    "candidate = ['this','is','a','test']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Corpus BLEU Score\n",
    "* calculating blew score for multiple sentences such as a paragraph or a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# two references for one document\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "references = [[['this','is','a','test'],['this','is','test']]]\n",
    "candidates = [['this','is','a','test']]\n",
    "score = corpus_bleu(references,candidates)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Individual n-gram Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# 1-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this','is','small','test']]\n",
    "candidate = ['this','is','a','test']\n",
    "score = sentence_bleu(reference,candidate,weights=(1,0,0,0))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 1-gram: 1.000000\n",
      "Individual 2-gram: 1.000000\n",
      "Individual 3-gram: 1.000000\n",
      "Individual 4-gram: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# n-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this','is','a','test']]\n",
    "candidate = ['this','is','a','test']\n",
    "print('Individual 1-gram: %f' %sentence_bleu(reference,candidate,weights=(1,0,0,0)))\n",
    "print('Individual 2-gram: %f' %sentence_bleu(reference,candidate,weights=(0,1,0,0)))\n",
    "print('Individual 3-gram: %f' %sentence_bleu(reference,candidate,weights=(0,0,1,0)))\n",
    "print('Individual 4-gram: %f' %sentence_bleu(reference,candidate,weights=(0,0,0,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cumulative n-gram Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0547686614863434e-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# 4-gram cumulative BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this','is','small','test']]\n",
    "candidate = ['this','is','a','test']\n",
    "score = sentence_bleu(reference,candidate,weights=(0.25,0.25,0.25,0.25))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative 1-gram: 0.750000\n",
      "Cumulative 2-gram: 0.500000\n",
      "Cumulative 3-gram: 0.000000\n",
      "Cumulative 4-gram: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/kuluruvineeth/anaconda3/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# cumulative BLEU scores\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['this','is','small','test']]\n",
    "candidate = ['this','is','a','test']\n",
    "print('Cumulative 1-gram: %f' %sentence_bleu(reference,candidate,weights=(1,0,0,0)))\n",
    "print('Cumulative 2-gram: %f' %sentence_bleu(reference,candidate,weights=(0.5,0.5,0,0)))\n",
    "print('Cumulative 3-gram: %f' %sentence_bleu(reference,candidate,weights=(0.33,0.33,0.33,0)))\n",
    "print('Cumulative 4-gram: %f' %sentence_bleu(reference,candidate,weights=(0.25,0.25,0.25,0.25)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# perfect match\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['the','quick','brown','fox','jumped','over','the','lazy','dog']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7506238537503395\n"
     ]
    }
   ],
   "source": [
    "# one word different\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['the','fast','brown','fox','jumped','over','the','lazy','dog']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4854917717073234\n"
     ]
    }
   ],
   "source": [
    "# two words different\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['the','fast','brown','fox','jumped','over','the','sleepy','dog']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# all words different\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['a','b','c','d','e','f','g','h','i']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7514772930752859\n"
     ]
    }
   ],
   "source": [
    "# shorter candidate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['the','quick','brown','fox','jumped','over','the']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7860753021519787\n"
     ]
    }
   ],
   "source": [
    "# longer candidate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['the','quick','brown','fox','jumped','over','the','lazy','dog']]\n",
    "candidate = ['the','quick','brown','fox','jumped','over','the','lazy','dog','from','space']\n",
    "score = sentence_bleu(reference,candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
